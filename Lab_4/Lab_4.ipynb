{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing is my own code, could be found [here](https://github.com/zer0deck/MLBM_Tclassifiers/blob/main/Data/Filtering.ipynb)\n",
    "\n",
    "This is my Article now publishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/zer0deck/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/zer0deck/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/zer0deck/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import text_filter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = open('Alice.txt', 'r')\n",
    "text = t.read()\n",
    "t.close\n",
    "\n",
    "text = text.split('CHAPTER I.')[2]\n",
    "text = text.split('END OF THE PROJECT GUTENBERG')[0]\n",
    "chapters = text.split('CHAPTER ')\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning text and tfidf vectorization\n",
    "clearText = text_filter(text = text)\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfs = tfidf.fit_transform(clearText.split(\"CHAPTER \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------------------------------------------------------------+\n",
      "| № of Chapter |                                 Top words                                  |\n",
      "+--------------+----------------------------------------------------------------------------+\n",
      "|      1       |   ['little' 'way' 'like' 'rabbit' 'time' 'think' 'thought' 'said' 'went'   |\n",
      "|              |                                   'door']                                  |\n",
      "|      2       |    ['little' 'mouse' 'said' 'thought' 'like' 'way' 'went' 'dear' 'pool'    |\n",
      "|              |                                  'cried']                                  |\n",
      "|      3       | ['said' 'mouse' 'dodo' 'know' 'soon' 'lory' 'thing' 'course' 'dry' 'race'] |\n",
      "|      4       |    ['little' 'said' 'rabbit' 'heard' 'thought' 'thing' 'quite' 'window'    |\n",
      "|              |                               'came' 'great']                              |\n",
      "|      5       |  ['said' 'caterpillar' 'pigeon' 'little' 'serpent' 'know' 'think' 'size'   |\n",
      "|              |                               'bit' 'tried']                               |\n",
      "|      6       |   ['said' 'cat' 'like' 'little' 'duchess' 'footman' 'baby' 'mad' 'know'    |\n",
      "|              |                                   'went']                                  |\n",
      "|      7       |   ['said' 'hatter' 'dormouse' 'march' 'hare' 'time' 'tea' 'know' 'went'    |\n",
      "|              |                                  'little']                                 |\n",
      "|      8       |    ['said' 'queen' 'head' 'king' 'went' 'soldiers' 'began' 'cat' 'like'    |\n",
      "|              |                                   'came']                                  |\n",
      "|      9       | ['said' 'turtle' 'mock' 'gryphon' 'duchess' 'queen' 'went' 'little' 'say'  |\n",
      "|              |                                   'day']                                   |\n",
      "|      10      |      ['said' 'gryphon' 'turtle' 'mock' 'dance' 'soup' 'voice' 'join'       |\n",
      "|              |                             'beautiful' 'know']                            |\n",
      "|      11      |   ['said' 'king' 'hatter' 'court' 'dormouse' 'witness' 'queen' 'rabbit'    |\n",
      "|              |                             'began' 'thought']                             |\n",
      "|      12      |   ['said' 'king' 'jury' 'little' 'queen' 'white' 'rabbit' 'know' 'head'    |\n",
      "|              |                                   'gave']                                  |\n",
      "+--------------+----------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#searching top n (10) words in chapter with TF-IDF except word 'alice'\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"№ of Chapter\", \"Top words\"]\n",
    "number = 1\n",
    "for block in chapters:\n",
    "    clearChapter = text_filter(text = block)\n",
    "    clearChapter = re.sub(r'alice', '', clearChapter)\n",
    "    response = tfidf.transform([clearChapter])\n",
    "    feature_array = np.array(tfidf.get_feature_names())\n",
    "    tfidf_sorting = np.argsort(response.toarray()).flatten()[::-1]\n",
    "    n = 10\n",
    "    top_n = feature_array[tfidf_sorting][:n]\n",
    "    table.add_row([str(number), str(top_n)])\n",
    "    number +=1\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['said' 'went' 'thought' 'say' 'looked' 'got' 'know' 'began' 'think'\n",
      " 'replied']\n"
     ]
    }
   ],
   "source": [
    "#top 10 verbs in sentences with 'alice'\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "aliceSentences = []\n",
    "verbs = ''\n",
    "for block in sentences:\n",
    "    clearSentence = text_filter(text = block)\n",
    "    if 'alice' in clearSentence:\n",
    "        aliceSentences.append(clearSentence)\n",
    "    else:\n",
    "        continue\n",
    "for block in aliceSentences:\n",
    "    s = nltk.pos_tag(block.split())\n",
    "    for w in s:\n",
    "        if 'VB' in w[1]:\n",
    "            verbs += w[0] + ' '\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "response = tfidf.transform([verbs])\n",
    "feature_array = np.array(tfidf.get_feature_names())\n",
    "tfidf_sorting = np.argsort(response.toarray()).flatten()[::-1]\n",
    "n = 10\n",
    "print(feature_array[tfidf_sorting][:n])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
