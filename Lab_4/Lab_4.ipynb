{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing is my own code, could be found [here](https://github.com/zer0deck/MLBM_Tclassifiers/blob/main/Data/Filtering.ipynb)\n",
    "\n",
    "This is my Article now publishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/zer0deck/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/zer0deck/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/zer0deck/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import text_filter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = open('Alice.txt', 'r')\n",
    "text = t.read()\n",
    "t.close\n",
    "\n",
    "text = text.split('CHAPTER I.')[2]\n",
    "text = text.split('END OF THE PROJECT GUTENBERG')[0]\n",
    "chapters = text.split('CHAPTER ')\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning text and tfidf vectorization\n",
    "clearText = text_filter(text = text)\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfs = tfidf.fit_transform(clearText.split(\"chapter \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------------------------------------------------------------+\n",
      "| № of Chapter |                                 Top words                                  |\n",
      "+--------------+----------------------------------------------------------------------------+\n",
      "|      1       | ['little' 'rabbit' 'key' 'way' 'bats' 'hole' 'door' 'like' 'eat' 'bottle'] |\n",
      "|      2       |    ['mouse' 'pool' 'little' 'cats' 'swam' 'said' 'mabel' 'dear' 'feet'     |\n",
      "|              |                                  'cried']                                  |\n",
      "|      3       |    ['said' 'mouse' 'dodo' 'race' 'lory' 'dry' 'prizes' 'thimble' 'know'    |\n",
      "|              |                                  'birds']                                  |\n",
      "|      4       |   ['little' 'window' 'rabbit' 'puppy' 'chimney' 'bottle' 'fan' 'gloves'    |\n",
      "|              |                               'said' 'room']                               |\n",
      "|      5       |  ['caterpillar' 'said' 'pigeon' 'serpent' 'youth' 'eggs' 'father' 'size'   |\n",
      "|              |                             'little' 'hookah']                             |\n",
      "|      6       |     ['said' 'cat' 'footman' 'baby' 'duchess' 'mad' 'pig' 'like' 'cook'     |\n",
      "|              |                                  'little']                                 |\n",
      "|      7       |  ['hatter' 'dormouse' 'said' 'march' 'hare' 'tea' 'time' 'twinkle' 'draw'  |\n",
      "|              |                                 'treacle']                                 |\n",
      "|      8       |       ['queen' 'said' 'gardeners' 'soldiers' 'king' 'hedgehog' 'cat'       |\n",
      "|              |                     'procession' 'executioner' 'game']                     |\n",
      "|      9       |     ['said' 'mock' 'turtle' 'gryphon' 'duchess' 'queen' 'moral' 'went'     |\n",
      "|              |                             'school' 'little']                             |\n",
      "|      10      |     ['turtle' 'mock' 'gryphon' 'said' 'dance' 'soup' 'join' 'whiting'      |\n",
      "|              |                           'lobsters' 'beautiful']                          |\n",
      "|      11      |    ['king' 'hatter' 'said' 'court' 'dormouse' 'witness' 'queen' 'jury'     |\n",
      "|              |                              'tarts' 'bread']                              |\n",
      "|      12      | ['said' 'king' 'jury' 'sister' 'dream' 'queen' 'rabbit' 'verses' 'jurymen' |\n",
      "|              |                                  'white']                                  |\n",
      "+--------------+----------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#searching top n (10) words in chapter with TF-IDF except word 'alice'\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"№ of Chapter\", \"Top words\"]\n",
    "number = 1\n",
    "for block in chapters:\n",
    "    clearChapter = text_filter(text = block)\n",
    "    clearChapter = re.sub(r'alice', '', clearChapter)\n",
    "    response = tfidf.transform([clearChapter])\n",
    "    feature_array = np.array(tfidf.get_feature_names())\n",
    "    tfidf_sorting = np.argsort(response.toarray()).flatten()[::-1]\n",
    "    n = 10\n",
    "    top_n = feature_array[tfidf_sorting][:n]\n",
    "    table.add_row([str(number), str(top_n)])\n",
    "    number +=1\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['said' 'went' 'thought' 'say' 'looked' 'replied' 'got' 'began' 'know'\n",
      " 'looking']\n"
     ]
    }
   ],
   "source": [
    "#top 10 verbs in sentences with 'alice'\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "aliceSentences = []\n",
    "verbs = ''\n",
    "for block in sentences:\n",
    "    clearSentence = text_filter(text = block)\n",
    "    if 'alice' in clearSentence:\n",
    "        aliceSentences.append(clearSentence)\n",
    "    else:\n",
    "        continue\n",
    "for block in aliceSentences:\n",
    "    s = nltk.pos_tag(block.split())\n",
    "    for w in s:\n",
    "        if 'VB' in w[1]:\n",
    "            verbs += w[0] + ' '\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "response = tfidf.transform([verbs])\n",
    "feature_array = np.array(tfidf.get_feature_names())\n",
    "tfidf_sorting = np.argsort(response.toarray()).flatten()[::-1]\n",
    "n = 10\n",
    "print(feature_array[tfidf_sorting][:n])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
